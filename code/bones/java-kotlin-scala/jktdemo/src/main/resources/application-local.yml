server:
  port: 8081
spring:
  application:
    name: dubbo-spring-boot-starter

swagger:
  enable: true

  freemarker:
    cache: false
    charset: UTF-8
    content-type: text/html
    suffix: .ftl
    check-template-location: true
    template-loader-path: classpath:/templates
    expose-request-attributes: true
    expose-session-attributes: true
    expose-spring-macro-helpers: true
    request-context-attribute: request
    settings:
      default_encoding: UTF-8
      output_encoding: UTF-8
      url_escaping_charset: UTF-8
      tag_syntax: auto_detect
      locale: zh_CN
      datetime_format: yyyy-MM-dd HH:mm:ss
      date_format: yyyy-MM-dd
      time_format: HH:mm:ss

  redis:
    database: 1
    host: 127.0.0.1
    port: 6379
    password:
    lettuce:
      pool:
        max-active:  100 # 连接池最大连接数（使用负值表示没有限制）
        max-idle: 10 # 连接池中的最大空闲连接
        min-idle: 5 # 连接池中的最小空闲连接
        max-wait: 6000 # 连接池最大阻塞等待时间（使用负值表示没有限制）
    timeout: 1000

  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/test
    username: root
    password: root
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 5
      maximum-pool-size: 15
      auto-commit: true
      idle-timeout: 30000
      pool-name: HikariCP
      max-lifetime: 1800000
      connection-timeout: 5000
      connection-test-query: SELECT 1

  rabbitmq:
    host: localhost
    port: 5672
    username: admin
    password: admin
    publisher-confirms: true
    virtual-host: my_vhost

  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer:
      retries: 3
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: -1
    consumer:
      auto-commit-interval: 1s
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      concurrency: 5
      ack-mode: manual
#      ack-count:
#      ack-time:

rocketmq:
  producer:
    groupName: sendGroup
    namesrvAddr: 127.0.0.1:9876
    default: false


#https://blog.csdn.net/weixin_42315600/article/details/88631796
#dubbo:
#  scan:
#    base-packages: com.sf.jkt.k.comp.connection.dubbo
#  protocol:
#    name: dubbo
#    port: 20880
#  registry:
#    address: zookeeper://127.0.0.1:2181

#mybatis-plus:
#  # 如果是放在src/main/java目录下 classpath:/com/yourpackage/*/mapper/*Mapper.xml
#  # 如果是放在resource目录 classpath:/mapper/*Mapper.xml
#  mapper-locations: classpath:/com/sf/jkt/k/auto/mapper/*Mapper.xml
#  #实体扫描，多个package用逗号或者分号分隔
#  typeAliasesPackage: com.com.sf.jkt.k.auto.*.entity
#  type-enums-package: com.sf.jkt.k.Util
#  global-config:
#    db-config:
#      #主键类型  0:"数据库ID自增", 1:"用户输入ID",2:"全局唯一ID (数字类型唯一ID)", 3:"全局唯一ID UUID";
#      id-type: 0
#      #驼峰下划线转换
#      db-column-underline: true
#      #mp2.3+ 全局表前缀 mp_
#      #table-prefix: mp_
#      #数据库大写下划线转换
#      #capital-mode: true
#      # Sequence序列接口实现类配置
#      #逻辑删除配置（下面3个配置）
#      logic-not-delete-value: 0
#      logic-delete-value: 1
#  configuration:
#    #配置返回数据库(column下划线命名&&返回java实体是驼峰命名)，自动匹配无需as（没开启这个，SQL需要写as： select user_id as userId）
#    map-underscore-to-camel-case: true
#    cache-enabled: false
#    #配置JdbcTypeForNull, oracle数据库必须配置
#    jdbc-type-for-null: 'null'

mhello:
  msg: "hello"



# 调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
xxl:
  job:
    admin:
      addresses: http://localhost:8080/xxl-job-admin
    executor:
      # 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
      appname: xxl-job-executor-user
      # 执行器IP [选填]：默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；
      ip:
      #执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；
      port: 9999
      # 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
      logpath:
      # 执行器日志保存天数 [选填] ：值大于3时生效，启用执行器Log文件定期清理功能，否则不生效；
      logretentiondays: -1
    # 执行器通讯TOKEN [选填]：非空时启用；
    accessToken:
